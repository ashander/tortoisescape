---
title: "Interior methods: exploration"
date: "`r date()`"
author: "Peter Ralph"
---

$$
\DeclareMathOperator{\grad}{\nabla}
$$

```{r setup, include=FALSE}
options(scipen=3)
fig.dim <- 5
knitr::opts_chunk$set(fig.height=fig.dim,fig.width=2*fig.dim,fig.align='center')
source("../inference/resistance-fns.R",chdir=TRUE)
source("../inference/diy-grid-generator.R",chdir=TRUE)
library(Matrix)
```


The general problem
===================

Let $R$ be a open subset of $\R^2$,
and suppose that $g$ and $a$
are nice enough functions on $R$ with $g > 0$.
Define the elliptic operator
$$\begin{aligned}
Lu(x) = g(x) \grad \cdot a(x) \grad u(x) .
\end{aligned}$$
Let $U = \{(x,y)\in R^2 : |x-y|>r\}$, for some $r$,
and suppose we also have a nonnegative function $f$ on $\partial U$.
Then define the function $h$ on $U$ to solve the Dirichlet problem
$$\begin{aligned}
    L_x h(x,y) + L_y h(x,y) &= -1 \qquad \text{ for } (x,y) \in U \\
    h(x,y) &= f(x,y) \qquad \text{ for } (x,y) \in \partial U .
\end{aligned}$$
where $L_x$ acts on the $x$-slot of $h$, etcetera.
We have noisy observations of $h$ in both the interior and boundary of $U$,
and would like to infer $f$, $g$, and $a$. 

If we forget about the product structure, then the above can be rewritten
$$\begin{aligned}
    L_x h(x,y) + L_y h(x,y) &= -1 \qquad \text{ for } (x,y) \in U \\
    h(x,y) &= f(x,y) \qquad \text{ for } (x,y) \in \partial U .
\end{aligned}$$



Weak inference
==============

As above, suppose that $g$, $b_1$, and $b_2$
are functions on $U$, with $g \ge 0$,
and that with $B=(b_1,b_2)$,
$$\begin{aligned}
    \Delta h(x) + B(x) \cdot \grad h(x) &= -g(x) \qquad \text{for } x \in U \\
    h(x) &= 0 \qquad \text{for }  x \in \partial U .
\end{aligned}$$
Then, suppose we have noisy observations of $h$.
Let's suppose that we use those noisy observations
to estimate $\int_U h(x) \phi(x) dx$ for test functions $\phi$
with some degree of accuracy that depends on $\phi$.

Suppose that $\phi$ and $\grad \phi$ vanish on $\partial_U$.
Integrating the equation above against $\phi$
and integrating by parts
we get that
$$\begin{aligned}
    0 &=
    \int \phi \left( \Delta h + B \cdot \grad h + g \right) dx \\
    &=
    \int h \left( \Delta \phi - \grad \cdot ( \phi B ) \right) dx + \int \phi g dx \\
    &=
    \int h \left( \Delta \phi - B \cdot \grad \phi - \phi \grad \cdot B \right) dx + \int \phi g dx 
\end{aligned}$$

Now suppose that $\{\phi_k\}$ is an orthnormal basis for $C^2_0(U)$,
and that 
$$\begin{aligned}
    b_1 &= \sum_k \beta_{1k} \phi_k \\
    b_2 &= \sum_k \beta_{2k} \phi_k \\
    g &= \sum_k \gamma{k} \phi_k .
\end{aligned}$$
Then the equation above is
$$\begin{aligned}
    \int h \Delta \phi dx
    &=
    \sum_k \int h \left( 
    \beta_{1k} \phi_k \partial_{x_1} \phi 
    + \beta_{2k} \phi_k \partial_{x_2} \phi 
    + \beta_{1k} \phi \partial_{x_1} \phi_k
    + \beta_{2k} \phi \partial_{x_2} \phi_k
      \right) dx
    - \gamma_k \int \phi \phi_k dx  \\
      &=
    \sum_k \left\{
     \beta_{1k} \int h ( 
         \phi_k \partial_{x_1} \phi 
         + \phi \partial_{x_1} \phi_k ) dx 
     + \beta_{2k} \int h ( 
         \phi_k \partial_{x_2} \phi 
         + \phi \partial_{x_2} \phi_k ) dx 
    - \gamma_k \int \phi \phi_k dx  
      \right\}
\end{aligned}$$

If furthermore we decompose
$$\begin{aligned}
\phi_k \partial_{x_1} \phi_\ell
+ \phi_\ell \partial_{x_1} \phi_k
  &=
  \sum_m \delta^1_{k\ell,m} \phi_m \\
\Delta \phi_\ell &= \sum_m \kappa_{\ell m} \phi_m ,
\end{aligned}$$
then 
$$\begin{aligned}
    \sum_m \kappa_{\ell m} \int h \phi_m dx
      &=
    \sum_k \left\{
     \beta_{1k} \sum_m \delta^1_{k\ell,m} \int h \phi_m dx
     + \beta_{1k} \sum_m \delta^2_{k\ell,m} \int h \phi_m dx
      \right\}
    - \gamma_\ell
\end{aligned}$$
Note that $\delta_{k\ell,m} = \delta_{\ell k,m}$.


This gives us a set of linear equations
that the coefficients $\beta$ and $\gamma$ solve.
We would like those that have to do with low frequencies
to only depend on other low frequencies,
i.e.,
that $\kappa$ and $\delta$ are "upper triangular".
In particular, it would be nice if we had
$\kappa_{\ell m} = 0$ for $m > \ell$
and
$\delta_{k \ell, m} = 0$ for 




Simple example
==============

Consider the following problem:
we are given a function $f(x)$ on $[0,1]$
and then suppose that $h(x,y)$ is a function on $U=[0,1]^2$
that solves
$$\begin{aligned}
 \Delta h(x,y) &= -1 \qquad \text{for } x\neq y \\
 h(x,x) &= f(x) \\
 0
 &=\partial_x h(x,0)
 =\partial_x h(x,1)
 =\partial_x h(0,y)
 =\partial_x h(1,y) .
\end{aligned}$$
Then, suppose that at a set of $\ell$ locations $(x_i,y_i)$
we have noisy observations of $h$:
$$\begin{aligned}
    H_i &= h(x_i,y_i) + \epsilon_i \\
    \epsilon_i &\sim N(0,\eta^2) .
\end{aligned}$$

**Question:** How do we infer $f(x)$?
*Note:* We won't use $h(x,y)=h(y,x)$ below, but should.

Here's a picture of the set-up.
The discrete analog of finding $h$ from $f$ is to solve 
$$\begin{aligned}
  Q_{-d,-d} h_{-d} &= - Q_{-d,d} f -1 \\
  h_d = f
\end{aligned}$$
```{r landscape}
n <- 20
# L is n^2 x n^2
L <- grid.adjacency(n)
L <- L-Diagonal(n=nrow(L),x=rowSums(L))
xvals <- (1:n-0.5)/n
yvals <- (1:n-0.5)/n
# generate a random f (length n)
f <- rexp(n)
# h is n x n
rhs <- h <- matrix( nrow=n, ncol=n )
diagsites <- which(row(h)==col(h))
diag(h) <- f
rhs[-diagsites] <- as.vector( -1 - L[-diagsites,diagsites]%*%f )
h[-diagsites] <- as.vector( solve( L[-diagsites,-diagsites], rhs[-diagsites] ) )
layout(t(1:2))
image(rhs,main="right-hand side")
image(h,main="h(x,y)")
```

If we denote by $\mathcal{H}(f)$ the solution to the equation above,
the log-likelihood is
$$\begin{aligned}
    \mathcal{L}(f)
    % &= \log \left(
    % \frac{\exp{\sum_{i=1}^\ell (H_i-\mathcal{H}(f)(x_i,y_i))/\eta^2}}{(2\pi\eta^2)^{\ell/2}} ,
    % \right)
    &=
    \sum_{i=1}^\ell (H_i-\mathcal{H}(f)(x_i,y_i))^2/\eta^2
    - \frac{\ell}{2}\log(2\pi) - \ell \log(\eta) .
\end{aligned}$$
The Frech\'et derivative of this with respect to $f$ is
$$\begin{aligned}
    \partial_f \mathcal{L}(f)
    &=
    \sum_{i=1}^\ell 2 (H_i-\mathcal{H}(z)(x_i,y_i)) \partial_f \mathcal{H}(f)(x_i,y_i) /\eta^2 .
\end{aligned}$$
Here $\partial_\psi \mathcal{H}(f)(x,y) = \lim_{\epsilon\to0} \frac{1}{\epsilon}(\mathcal{H}(f+\epsilon\psi)-\mathcal{H}(f))$.
Note that
$$\begin{aligned}
 \Delta \mathcal{H}(f+g)(x,y) &= -1 \qquad \text{for } x\neq y \\
 \Delta \mathcal{H}(f)(x,y) &= -1 \qquad \text{for } x\neq y \\
 \mathcal{H}(f+g)(x,x) &= f(x)+g(x) \\
 \mathcal{H}(f)(x,x) &= f(x) ,
\end{aligned}$$
so that $u_\psi=\mathcal{H}(f+\psi)-\mathcal{H}(f)$,
in addition to the boundary conditions,
is harmonic off the diagonal and equal to $g$ on the diagonal:
$$\begin{aligned}
 \Delta u(x,y) &= 0 \qquad \text{for } x\neq y \\
 u(x,x) &= \psi(x) .
\end{aligned}$$

